{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dnhshl/cc-ai/blob/main/iris-neural-network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkgMvGyySG1v"
      },
      "source": [
        "# Iris Neural Network\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Artifical Neural Networks are quickly becoming one of the most popular and widely used mechanisms in Machine Learning and Data Analysis. In the last number of years, numerous libraries and software has been developed to equip programmers with a set of tools for modeling and analysing data in order to recognise patterns and make predictions using large data sets. In today's age of [Big Data](https://en.wikipedia.org/wiki/Big_data) it is important to try make sense of all of the data we have in society. This could range from social media pattern recognitions from anything to finance and economic trends. The reality is that today we have more data in existence than ever before and it growing at a vast and exponential rate.\n",
        "\n",
        "Artifical Neural Networks aim to mimic and replicate the neurons of a human brain and using the power of the complex mathematical functions allow us to process and model data in such a way that we can form rational assumptions on a given data set.\n",
        "\n",
        "Given the sheer amount of data out there it is important to note that data we may analyse is often subject to human error and may not always hold a valid essense of truth. For the purpose of this example we will take a look at the [Iris Data Set](https://archive.ics.uci.edu/ml/datasets/iris).\n",
        "\n",
        "More information on the data set can be found on the link provided above or on the front page [README of this repository](https://github.com/damiannolan/iris-neural-network).\n",
        "\n",
        "Throughout the notebook we aim to build an Artifical Neural Network capable of making predictions of species of Iris Flowers using [Keras](https://keras.io) - Keras is a high-level neural networks API, written in Python and capable of running on top of [Tensorflow](https://www.tensorflow.org/).\n",
        "\n",
        "So without further ado, lets get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ko_gSQdISG1z"
      },
      "source": [
        "## Importing the data set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "# Convert the dataset to a pandas DataFrame for easier manipulation\n",
        "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "iris_df['target'] = iris.target\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(iris_df.head())\n"
      ],
      "metadata": {
        "id": "bACbp9qxSnCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmZ2hbaASG11"
      },
      "source": [
        "## Inputs and Outputs\n",
        "### Data Investigation and Classification\n",
        "\n",
        "Before trying to create a model for our Neural Network we first need to investigate our data and determine what will be the inputs and what will be our outputs. The CSV file provided contains 5 columns with:\n",
        "\n",
        "- Sepal Length\n",
        "- Sepal Width\n",
        "- Petal Length\n",
        "- Petal Width\n",
        "- Species\n",
        "\n",
        "Judging by the fact that we are trying to make predictions we must split our data set into sets of:\n",
        "\n",
        "- Inputs - Numerical data values\n",
        "- Outputs - Classification of Iris Flower species\n",
        "\n",
        "\n",
        "Now that we have the data set loaded we can extract the data we need into appropriate data sets in preparation for training and testing our Model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras as kr"
      ],
      "metadata": {
        "id": "oh2uLNvVWszQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9OIZov0SG11"
      },
      "outputs": [],
      "source": [
        "# The inputs are four floats: sepal length, sepal width, petal length, petal width.\n",
        "inputs  = np.array(iris.data)\n",
        "\n",
        "# Outputs are 0 (=setosa), 1 (=versicolor) or 2 (=virginica).\n",
        "outputs = np.array(iris.target)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeyQvfG_SG11"
      },
      "source": [
        "## Categorical Classification\n",
        "\n",
        "Here we are using the Keras utility `to_categorical()` to allow us to turn our output categories into binary class matrices. This is often refered to as \"One-Hot\" encoding. This is for use with categorical_crossentropy and classification of our species (setosa, versicolor and virginica).\n",
        "\n",
        "Each Species will be represented as a binary class matrix.\n",
        "\n",
        "- Setosa [1 0 0]\n",
        "- Versicolor [0 1 0]\n",
        "- Virginica [0 0 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R82YIJUBSG11"
      },
      "outputs": [],
      "source": [
        "# Encode the category integers as binary categorical vairables.\n",
        "outputs_cats = kr.utils.to_categorical(outputs)\n",
        "outputs_cats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoDuzCN1SG12"
      },
      "source": [
        "## Divide & Conquer\n",
        "### Splitting the data\n",
        "\n",
        "We can now randomly split the data into two sets for:\n",
        "\n",
        "- Training\n",
        "- Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXJTjADASG12"
      },
      "outputs": [],
      "source": [
        "# Split the input and output data sets into training and test subsets.\n",
        "inds = np.random.permutation(len(inputs))\n",
        "train_inds, test_inds = np.array_split(inds, 2)\n",
        "inputs_train, outputs_train = inputs[train_inds], outputs_cats[train_inds]\n",
        "inputs_test,  outputs_test  = inputs[test_inds],  outputs_cats[test_inds]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z32RO-wLSG12"
      },
      "source": [
        "## Creating a Model\n",
        "\n",
        "Below we can see an example of a how a Neural Network can be visualized. Every Neural Network is made up of these three main consituents.\n",
        "\n",
        "- Input Layer\n",
        "- $x$ number of Hidden Layers\n",
        "- Output Layer\n",
        "\n",
        "![neural_net](https://github.com/damiannolan/iris-neural-network/blob/master/img/neural_net.jpeg?raw=1)\n",
        "\n",
        "### Keras Models\n",
        "\n",
        "Keras offers a very useful and high level API to handle creation of Neural Networks. The [Keras Sequential Model](https://keras.io/getting-started/sequential-model-guide/) is defined as a *linear stack of layers*. This is perfect for what we need to create an Artificial Neural Network consisting of Input, Output and Hidden nodes. We define our Model and add the layers to it.\n",
        "\n",
        "We are trying to create a model that will look somewhat similar to below:\n",
        "\n",
        "![iris_model](https://github.com/damiannolan/iris-neural-network/blob/master/img/iris_model.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoVcNM6CSG13"
      },
      "outputs": [],
      "source": [
        "# Create a neural network.\n",
        "model = kr.models.Sequential()\n",
        "\n",
        "# Add an initial layer with 4 input nodes, and a hidden layer with 16 nodes.\n",
        "model.add(kr.layers.Dense(16, input_shape=(4,)))\n",
        "# Apply the sigmoid activation function to that layer.\n",
        "model.add(kr.layers.Activation(\"sigmoid\"))\n",
        "# Add another layer, connected to the layer with 16 nodes, containing three output nodes.\n",
        "model.add(kr.layers.Dense(3))\n",
        "# Use the softmax activation function there.\n",
        "model.add(kr.layers.Activation(\"softmax\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHMc2_DrSG13"
      },
      "source": [
        "## Activation Functions\n",
        "\n",
        "An [Activation Function](https://en.wikipedia.org/wiki/Activation_function) in a Neural Network defines the output of a given node given its input or set of inputs. Above we applying two activation functions in separate layers.\n",
        "\n",
        "### Sigmoid\n",
        "A sigmoid function is a mathematical function having an \"S\" shaped curve (sigmoid curve). Often, sigmoid function refers to the special case of the logistic function shown in the first figure and defined by the formula:\n",
        "\n",
        "\n",
        "![sigmoid](https://github.com/damiannolan/iris-neural-network/blob/master/img/sigmoid.svg?raw=1)\n",
        "\n",
        "Below we see a plot of the \"S\" shaped curved or \"Sigmoid Curve\".\n",
        "\n",
        "![curve](https://github.com/damiannolan/iris-neural-network/blob/master/img/Logistic-curve.svg.png?raw=1)\n",
        "\n",
        "It's usage in neural network are:\n",
        "1. Activation function that transform linear inputs to nonlinear outputs.\n",
        "2. Bound output to between 0 and 1 so that it can be interpreted as a probability.\n",
        "3. Make computation easier than arbitrary activation functions.\n",
        "\n",
        "### Softmax\n",
        "\n",
        "[Softmax regression](http://ufldl.stanford.edu/tutorial/supervised/SoftmaxRegression/) (or multinomial logistic regression) is a generalization of logistic regression to the case where we want to handle multiple classes.\n",
        "\n",
        "Softmax regression is defined by the mathematical formula:\n",
        "\n",
        "![softmax](https://github.com/damiannolan/iris-neural-network/blob/master/img/softmax.svg?raw=1)\n",
        "\n",
        "Here are using Softmax to allow us to let our data flow through the hidden layers and essentially end up as one of our defined classes:\n",
        "\n",
        "- Setosa\n",
        "- Versicolor\n",
        "- Virginica\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehVtZl78SG14"
      },
      "outputs": [],
      "source": [
        "# Display our Model using the summary function\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLAAp1LuSG14"
      },
      "source": [
        "## Configure the Model for training and fit the training data\n",
        "\n",
        "We configure the Model using the `compile()` function defined in the [Keras Model API](https://keras.io/models/model/).\n",
        "We define an Optimizer, a Loss function and an additional metric - accuracy.\n",
        "\n",
        "So before we can use our Model for we must first train it. Using the training data subset which we extracted before we can now fit it to our Model.\n",
        "\n",
        "The goal here is for the Optimizer to essentially minimize the Loss.\n",
        "\n",
        "We fit the model passing our inputs and our expected outputs and train it across 100 \"Epochs\" or training cycles. On each iteration we improve the improve the accuracy and miniize the loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICTVp2INSG15"
      },
      "outputs": [],
      "source": [
        "# Configure the model for training.\n",
        "# Uses the adam optimizer and categorical cross entropy as the loss function.\n",
        "# Add in some extra metrics - accuracy being the only one.\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model using our training data.\n",
        "model.fit(inputs_train, outputs_train, epochs=100, batch_size=1, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xiLUkr6SG15"
      },
      "source": [
        "## Evaluate the Loss and Accuracy of the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEyCYFUqSG15"
      },
      "source": [
        "Now that we have trained our Model we can evalate it using the test data which we extracted before. Using `evaluate()` we expect our return values of loss and accuracy for our given Test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MNgM0mySG15"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model using the test data set.\n",
        "loss, accuracy = model.evaluate(inputs_test, outputs_test, verbose=1)\n",
        "\n",
        "# Output the accuracy of the model.\n",
        "print(\"\\n\\nLoss: %6.4f\\tAccuracy: %6.4f\" % (loss, accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVkEHg4LSG15"
      },
      "source": [
        "## Making predictions using the Model\n",
        "\n",
        "To make predictions using our Model we must first prepare the input data to be what the model expects. Here we use a couple of Numpy functions such as `around()` and `expand_dims()` to prepare the input data for prediction.\n",
        "\n",
        "We can then pass get our prediction as a String value from `outputs_vals` which defined earlier in the Notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O61j6O8ISG15"
      },
      "outputs": [],
      "source": [
        "# Predict the class of a single flower.\n",
        "prediction = np.around(model.predict(np.expand_dims(inputs_test[0], axis=0))).astype(int)[0]\n",
        "\n",
        "print(\"Actual: %s\\tEstimated: %s\" % (outputs_test[0].astype(int), prediction))\n",
        "print(\"That means it's a %s\" % outputs_vals[prediction.astype(bool)][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpOaB5z_SG16"
      },
      "source": [
        "## Saving and Loading the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_2CLknkSG16"
      },
      "source": [
        "Keras offers a very simplistic way to save and load your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdnr7CyeSG16"
      },
      "outputs": [],
      "source": [
        "# Save the model to a file for later use.\n",
        "model.save(\"iris_neural_network.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcdcUlfASG16"
      },
      "source": [
        "We can easily reload the model in another script using `model = load_model(\"path_to_model.h5\")`"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}